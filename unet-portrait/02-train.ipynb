{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 参数配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "BASE_DIR = os.getcwd()\n",
    "sys.path.append(os.path.join(BASE_DIR, '..'))\n",
    "from functools import partial\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from nets.unet import Unet\n",
    "from nets.unet_training import CE, Generator, LossHistory\n",
    "from utils.metrics import f_score\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0,
     18,
     27
    ]
   },
   "outputs": [],
   "source": [
    "def get_train_step_fn():\n",
    "    @tf.function\n",
    "    def train_step(images, labels, net, optimizer, loss):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # 计算loss\n",
    "            prediction = net(images, training=True)\n",
    "            # print(\"loss input: {} {}\".format(labels.shape, prediction.shape))\n",
    "            loss_value = loss(labels, prediction)\n",
    "\n",
    "        grads = tape.gradient(loss_value, net.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, net.trainable_variables))\n",
    "        \n",
    "        _f_score = f_score()(labels, prediction)\n",
    "        return loss_value, _f_score\n",
    "    return train_step\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def val_step(images, labels, net, loss):\n",
    "    # 计算loss\n",
    "    prediction = net(images, training=False)\n",
    "    loss_value = loss(labels, prediction)\n",
    "    \n",
    "    _f_score = f_score()(labels, prediction)\n",
    "    return loss_value, _f_score\n",
    "\n",
    "\n",
    "def fit_one_epoch(net, loss, optimizer, epoch, epoch_size, epoch_size_val, gen, genval, Epoch, train_step):\n",
    "    total_loss = 0\n",
    "    total_f_score = 0\n",
    "\n",
    "    val_loss = 0\n",
    "    val_f_score = 0\n",
    "    with tqdm(total=epoch_size,desc=f'Epoch {epoch + 1}/{Epoch}',postfix=dict,mininterval=0.3) as pbar:\n",
    "        for iteration, batch in enumerate(gen):\n",
    "            if iteration >= epoch_size:\n",
    "                break\n",
    "            images, labels = batch[0], batch[1]\n",
    "            labels = tf.cast(tf.convert_to_tensor(labels), tf.float32)\n",
    "\n",
    "            loss_value, _f_score = train_step(images, labels, net, optimizer, loss)\n",
    "            total_loss += loss_value.numpy()\n",
    "            total_f_score += _f_score.numpy()\n",
    "\n",
    "            pbar.set_postfix(**{'Total Loss'        : total_loss / (iteration + 1), \n",
    "                                'Total f_score'     : total_f_score / (iteration + 1),\n",
    "                                'lr'                : optimizer._decayed_lr(tf.float32).numpy()})\n",
    "            pbar.update(1)\n",
    "        \n",
    "    print('Start Validation')\n",
    "    with tqdm(total=epoch_size_val, desc=f'Epoch {epoch + 1}/{Epoch}',postfix=dict,mininterval=0.3) as pbar:\n",
    "        for iteration, batch in enumerate(genval):\n",
    "            if iteration>=epoch_size_val:\n",
    "                break\n",
    "            images, labels = batch[0], batch[1]\n",
    "            labels = tf.convert_to_tensor(labels)\n",
    "\n",
    "            loss_value, _f_score = val_step(images, labels, net, loss)\n",
    "            val_loss            += loss_value.numpy()\n",
    "            val_f_score         += _f_score.numpy()\n",
    "\n",
    "            pbar.set_postfix(**{'Val Loss'      : val_loss / (iteration + 1), \n",
    "                                'Val f_score'   : val_f_score / (iteration + 1)})\n",
    "            pbar.update(1)\n",
    "\n",
    "    logs = {'loss': total_loss/(epoch_size+1), 'val_loss': val_loss/(epoch_size_val+1)}\n",
    "    loss_history.on_epoch_end([], logs)\n",
    "    print('Finish Validation')\n",
    "    print('Epoch:' + str(epoch+1) + '/' + str(Epoch))\n",
    "    print('Total Loss: %.4f || Val Loss: %.4f ' % (total_loss/(epoch_size+1),val_loss/(epoch_size_val+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日志文件夹位于:/mnt/cd1/home/teacher/notebooks/cv_project_2days/image_segmentation/unet-portrait/logs/loss_2021_08_24_11_40_08\n"
     ]
    }
   ],
   "source": [
    "# step0：参数配置\n",
    "# dataset_path = r\"G:\\deep_learning_data\\EG_dataset\\voc_format\"  # local \n",
    "dataset_path = os.path.join(BASE_DIR, \"..\", \"data\", \"dataset\", \"voc_format\")  #  linux \n",
    "model_path = os.path.join(BASE_DIR, \"data\", \"model_data\", \"unet_voc.h5\") # 预训练模型\n",
    "\n",
    "max_epoch = 100  # 总迭代轮\n",
    "Batch_size = 1  # 去修改下\n",
    "inputs_size = [224, 224, 3]\n",
    "num_classes = 2  # 模型输出通道数， 这包含背景类别数，本例中为 1+1=2   # \n",
    "lr = 1e-4\n",
    "decay_rate = 0.95  # 指数衰减参数，每个epoch之后，学习率衰减率\n",
    "\n",
    "import datetime\n",
    "curr_time = datetime.datetime.now()\n",
    "time_str = datetime.datetime.strftime(curr_time, '%Y_%m_%d_%H_%M_%S')\n",
    "loss_history = LossHistory(\"logs/\", time_str)\n",
    "log_dir = os.path.join(BASE_DIR, \"logs\", \"loss_\" + time_str)\n",
    "print(\"日志文件夹位于:{}\".format(log_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据集创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/cd1/home/teacher/notebooks/cv_project_2days/image_segmentation/unet-portrait/../data/dataset/voc_format/ImageSets/Segmentation/train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-b27e6cbb2f71>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# step1：数据集创建\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ImageSets/Segmentation/train.txt\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"r\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m     \u001B[0mtrain_lines\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreadlines\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ImageSets/Segmentation/val.txt\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"r\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mval_lines\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreadlines\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/mnt/cd1/home/teacher/notebooks/cv_project_2days/image_segmentation/unet-portrait/../data/dataset/voc_format/ImageSets/Segmentation/train.txt'"
     ]
    }
   ],
   "source": [
    "# step1：数据集创建\n",
    "with open(os.path.join(dataset_path, \"ImageSets/Segmentation/train.txt\"), \"r\") as f:\n",
    "    train_lines = f.readlines()\n",
    "with open(os.path.join(dataset_path, \"ImageSets/Segmentation/val.txt\"), \"r\") as f:\n",
    "    val_lines = f.readlines()\n",
    "\n",
    "epoch_size = len(train_lines) // Batch_size  # 计算一个epoch有几个iteration\n",
    "epoch_size_val = len(val_lines) // Batch_size\n",
    "\n",
    "#  利用生成器创建dataset\n",
    "gen = Generator(Batch_size, train_lines, inputs_size, num_classes, dataset_path)\n",
    "gen = tf.data.Dataset.from_generator(partial(gen.generate, random_data=True), (tf.float32, tf.float32))\n",
    "gen = gen.shuffle(buffer_size=Batch_size).prefetch(buffer_size=Batch_size)\n",
    "\n",
    "gen_val = Generator(Batch_size, val_lines, inputs_size, num_classes, dataset_path)\n",
    "gen_val = tf.data.Dataset.from_generator(partial(gen_val.generate, random_data=False), (tf.float32, tf.float32))\n",
    "gen_val = gen_val.shuffle(buffer_size=Batch_size).prefetch(buffer_size=Batch_size)\n",
    "\n",
    "if epoch_size == 0 or epoch_size_val == 0:\n",
    "    raise ValueError(\"数据集过小，无法进行训练，请扩充数据集。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     9
    ]
   },
   "outputs": [],
   "source": [
    "class Generator(object):\n",
    "    def __init__(self,batch_size,train_lines,image_size,num_classes,dataset_path):\n",
    "        self.batch_size     = batch_size\n",
    "        self.train_lines    = train_lines\n",
    "        self.train_batches  = len(train_lines)\n",
    "        self.image_size     = image_size\n",
    "        self.num_classes    = num_classes\n",
    "        self.dataset_path   = dataset_path\n",
    "\n",
    "    def get_random_data(self, image, label, input_shape, jitter=.3, hue=.1, sat=1.5, val=1.5):\n",
    "        label = Image.fromarray(np.array(label))\n",
    "\n",
    "        h, w = input_shape\n",
    "        # resize image\n",
    "        rand_jit1 = rand(1-jitter,1+jitter)\n",
    "        rand_jit2 = rand(1-jitter,1+jitter)\n",
    "        new_ar = w/h * rand_jit1/rand_jit2\n",
    "\n",
    "        scale = rand(0.25, 2)\n",
    "        if new_ar < 1:\n",
    "            nh = int(scale*h)\n",
    "            nw = int(nh*new_ar)\n",
    "        else:\n",
    "            nw = int(scale*w)\n",
    "            nh = int(nw/new_ar)\n",
    "        image = image.resize((nw,nh), Image.BICUBIC)\n",
    "        label = label.resize((nw,nh), Image.NEAREST)\n",
    "        label = label.convert(\"L\")\n",
    "        \n",
    "        # flip image or not\n",
    "        flip = rand()<.5\n",
    "        if flip: \n",
    "            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            label = label.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "        # place image\n",
    "        dx = int(rand(0, w-nw))\n",
    "        dy = int(rand(0, h-nh))\n",
    "        new_image = Image.new('RGB', (w,h), (128,128,128))\n",
    "        new_label = Image.new('L', (w,h), (0))\n",
    "        new_image.paste(image, (dx, dy))\n",
    "        new_label.paste(label, (dx, dy))\n",
    "        image = new_image\n",
    "        label = new_label\n",
    "\n",
    "        # distort image\n",
    "        hue = rand(-hue, hue)\n",
    "        sat = rand(1, sat) if rand()<.5 else 1/rand(1, sat)\n",
    "        val = rand(1, val) if rand()<.5 else 1/rand(1, val)\n",
    "        x = cv2.cvtColor(np.array(image,np.float32)/255, cv2.COLOR_RGB2HSV)\n",
    "        x[..., 0] += hue*360\n",
    "        x[..., 0][x[..., 0]>1] -= 1\n",
    "        x[..., 0][x[..., 0]<0] += 1\n",
    "        x[..., 1] *= sat\n",
    "        x[..., 2] *= val\n",
    "        x[x[:,:, 0]>360, 0] = 360\n",
    "        x[:, :, 1:][x[:, :, 1:]>1] = 1\n",
    "        x[x<0] = 0\n",
    "        image_data = cv2.cvtColor(x, cv2.COLOR_HSV2RGB)*255\n",
    "        return image_data,label\n",
    "        \n",
    "    def generate(self, random_data=True):\n",
    "        i = 0\n",
    "        length = len(self.train_lines)\n",
    "        inputs = []\n",
    "        targets = []\n",
    "        while True:\n",
    "            if i == 0:\n",
    "                shuffle(self.train_lines)\n",
    "            annotation_line = self.train_lines[i]\n",
    "            name = annotation_line.split()[0]\n",
    "\n",
    "            # 从文件中读取图像\n",
    "            jpg = Image.open(os.path.join(os.path.join(self.dataset_path, \"JPEGImages\"), name + \".png\"))\n",
    "            png = Image.open(os.path.join(os.path.join(self.dataset_path, \"SegmentationClass\"), name + \"_matte.png\"))\n",
    "\n",
    "            if random_data:\n",
    "                jpg, png = self.get_random_data(jpg, png, (int(self.image_size[1]), int(self.image_size[0])))\n",
    "            else:\n",
    "                # letterbox 表示等长宽比缩放图片，不足地方用灰色补\n",
    "                jpg, png = letterbox_image(jpg, png, (int(self.image_size[1]), int(self.image_size[0])))\n",
    "\n",
    "            # img的处理\n",
    "            inputs.append(np.array(jpg)/255)\n",
    "            # 标签的处理：处理为float类型的标签，不适合用int（非0即1，非黑即白的形式，因为边界需要过渡）\n",
    "            png = np.array(png)/255  # 转为[0, 1]\n",
    "            png_cp = png.copy()\n",
    "            h, w, _ = self.image_size\n",
    "\n",
    "            # 如果采用one-hot效果就会比较差，采用连续变量会比较好\n",
    "            seg_labels = np.zeros((h, w, self.num_classes+1))  # 增加1个通道是为匹配loss计算时候提出最后一个通道\n",
    "            seg_labels[:, :, 0] = 1 - png_cp    # 第0通道表示背景\n",
    "            seg_labels[:, :, 1] = png_cp        # 第1通道表示人像（前景）\n",
    "\n",
    "            targets.append(seg_labels)\n",
    "\n",
    "            i = (i + 1) % length\n",
    "            if len(targets) == self.batch_size:\n",
    "                tmp_inp = np.array(inputs)\n",
    "                tmp_targets = np.array(targets)\n",
    "                inputs = []\n",
    "                targets = []\n",
    "                # (1, 512, 512, 3) (1, 512, 512, cls_num + 1)  # 这里的cls_num包括了背景类别\n",
    "                yield tmp_inp, tmp_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1800 samples, val on 200 samples, with batch size 1.\n"
     ]
    }
   ],
   "source": [
    "print('Train on {} samples, val on {} samples, with batch size {}.'.format(len(train_lines), len(val_lines), Batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 观察gen生成器中产生的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(gen):\n",
    "    if i > 1:\n",
    "        break\n",
    "    img, labels = batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3) (1, 224, 224, 3)\n",
      "tf.Tensor([0.6656807  0.32050315 0.25912893], shape=(3,), dtype=float32)\n",
      "tf.Tensor([0. 1. 0.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape, labels.shape)\n",
    "print(img[0, 100, 100, :])\n",
    "print(labels[0, 100, 100, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f539797a130>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_numpy = labels.numpy()[0,:,:,1]\n",
    "print(label_numpy.shape)\n",
    "plt.imshow(label_numpy, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.创建model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping loading of weights for layer conv2d_8 due to mismatch in shape ((1, 1, 64, 2) vs (21, 64, 1, 1)).\n",
      "WARNING:tensorflow:Skipping loading of weights for layer conv2d_8 due to mismatch in shape ((2,) vs (21,)).\n"
     ]
    }
   ],
   "source": [
    "# step2： 创建model\n",
    "model = Unet(inputs_size, num_classes)  # 需要传入输入大小和最终输出通道数\n",
    "model.load_weights(model_path, by_name=True, skip_mismatch=True)  # 加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# step3：创建loss及优化器\n",
    "loss = CE()\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=lr, decay_steps=epoch_size,decay_rate=decay_rate, staircase=True)\n",
    "optimizer = Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   1%|          | 13/1800 [00:05<11:48,  2.52it/s, Total Loss=2.17, Total f_score=0.344, lr=1e-04] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-15-d4ff77e922d7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# step4：迭代训练\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_epoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0mfit_one_epoch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepoch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepoch_size_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgen\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgen_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_epoch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mget_train_step_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0mpath_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlog_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"model_weight_{}.h5\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime_str\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave_weights\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath_model\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-6-d835d0e07c34>\u001B[0m in \u001B[0;36mfit_one_epoch\u001B[0;34m(net, loss, optimizer, epoch, epoch_size, epoch_size_val, gen, genval, Epoch, train_step)\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m             \u001B[0mloss_value\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_f_score\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnet\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 42\u001B[0;31m             \u001B[0mtotal_loss\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mloss_value\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     43\u001B[0m             \u001B[0mtotal_f_score\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0m_f_score\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36mnumpy\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1061\u001B[0m     \"\"\"\n\u001B[1;32m   1062\u001B[0m     \u001B[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1063\u001B[0;31m     \u001B[0mmaybe_arr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1064\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mmaybe_arr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmaybe_arr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mmaybe_arr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1065\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36m_numpy\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1027\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1028\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1029\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_numpy_internal\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1030\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1031\u001B[0m       \u001B[0msix\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_status_to_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# step4：迭代训练\n",
    "for epoch in range(max_epoch):\n",
    "    fit_one_epoch(model, loss, optimizer, epoch, epoch_size, epoch_size_val, gen, gen_val, max_epoch, get_train_step_fn())\n",
    "    path_model = os.path.join(log_dir, \"model_weight_{}.h5\".format(time_str))\n",
    "    model.save_weights(path_model)\n",
    "    print(\"Epoch:{}, model save at :{}\".format(epoch, path_model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}